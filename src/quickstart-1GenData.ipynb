{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Jupyter Notebook pairs a frame of image data with its ground truth counterpart (placed by the user in \"quickstart-data\"),\n",
    "# and splits this pair of data into cubic volumes that are generated in the folder \"quickstart-gendata\"\n",
    "\n",
    "# Import libraries\n",
    "\n",
    "import numpy as np\n",
    "import skimage\n",
    "from skimage.util.shape import view_as_blocks\n",
    "#import skimage.external.tifffile\n",
    "import tifffile\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "#from aicsimageio import AICSImage\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have a frame (and its ground truth) that you would wish to generate cubic data from, place them in the \"quickstart-data\" folder.\n",
    "# Then replace the image_path and mask_path to point to these files.\n",
    "\n",
    "# Change these paths for YOUR images.\n",
    "image_path = r\"/Users/dnadeem/Desktop/dl/pyLattice_deepLearning/src/quickstart-data/train_data_input.tif\"\n",
    "mask_path= r\"/Users/dnadeem/Desktop/dl/pyLattice_deepLearning/src/quickstart-data/mask_all_frames_modified.tif\"\n",
    "split_directory=\"quickstart-gendata/\"\n",
    "\n",
    "\n",
    "\n",
    "# The side length of each cube (pixels). Will create patches with dimension (cube_size, cube_size, cube_size).\n",
    "cube_size = 32\n",
    "# Trying to get coverage of whole large dataset frame. Can change once we use more frames of our large data\n",
    "train_split = 0.8 \n",
    "\n",
    "# Create train and test folders in the split_directory.\n",
    "if \"train\" not in os.listdir(split_directory):\n",
    "    os.mkdir(split_directory+\"train/\")\n",
    "if \"test\" not in os.listdir(split_directory):\n",
    "    os.mkdir(split_directory+\"test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 55, 258, 275)\n",
      "(100, 55, 258, 275)\n"
     ]
    }
   ],
   "source": [
    "# Read the image as an array\n",
    "latticeMovieImage = tifffile.imread(image_path)\n",
    "latticeMovieMask = tifffile.imread(mask_path)\n",
    "#load tiff file to test \n",
    "# train_img = AICSImage(image_path)\n",
    "# print(train_img.dims)\n",
    "# latticeMovieImage = train_img.data\n",
    "# latticeMovieImage = latticeMovieImage[:,0,:,:,:]\n",
    "# labels_img = AICSImage(mask_path)\n",
    "# print(labels_img.dims)\n",
    "# latticeMovieMask = labels_img.data\n",
    "# latticeMovieMask = latticeMovieMask[:,0,:,:,:]\n",
    "\n",
    "print(latticeMovieImage.shape)\n",
    "print(latticeMovieMask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.amax(latticeMovieMask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image cropped to: 32, 256, 256\n",
      "Image cropped to: 32, 256, 256\n",
      "Image cropped to: 32, 256, 256\n",
      "Image cropped to: 32, 256, 256\n",
      "Image cropped to: 32, 256, 256\n",
      "(5, 32, 256, 256)\n",
      "(5, 32, 256, 256)\n",
      "255.0\n"
     ]
    }
   ],
   "source": [
    "# If you need to invert the mask, use the line below\n",
    "# latticeMovieMask = np.absolute(latticeMovieMask - 255.0)\n",
    "\n",
    "frames = latticeMovieImage.shape[0]\n",
    "latticeMovieImage_all = []\n",
    "latticeMovieMask_all = []\n",
    "frames = 5\n",
    "for frame in range(frames):\n",
    "    offset=np.asarray([0,0,0])\n",
    "    \n",
    "    x_extra = latticeMovieImage[frame].shape[2]%cube_size\n",
    "    x_size = latticeMovieImage[frame].shape[2] - x_extra\n",
    "    if offset[0] > x_extra:\n",
    "        print(\"1st dim offset exceeds image dim\")\n",
    "        offset[0] = 0\n",
    "        \n",
    "    y_extra = latticeMovieImage[frame].shape[1]%cube_size\n",
    "    y_size = latticeMovieImage[frame].shape[1] - y_extra\n",
    "    if offset[1] > y_extra:\n",
    "        print(\"2st dim offset exceeds image dim\")\n",
    "        offset[1] = 0\n",
    "        \n",
    "    z_extra = latticeMovieImage[frame].shape[0]%cube_size\n",
    "    z_size = latticeMovieImage[frame].shape[0] - z_extra\n",
    "    if offset[2] > z_extra:\n",
    "        print(\"3rd dim offset exceeds image dim\")\n",
    "        offset[2] = 0\n",
    "    \n",
    "    # After calculating the extra pixels, we crop our frame so that the cubes can be perfectly divided.\n",
    "    latticeMovieImage_frame = latticeMovieImage[frame,offset[0]:z_size+offset[0], offset[1]:y_size+offset[1], offset[2]:x_size+offset[2]]\n",
    "    latticeMovieMask_frame = latticeMovieMask[frame,offset[0]:z_size+offset[0], offset[1]:y_size+offset[1], offset[2]:x_size+offset[2]]\n",
    "    print(\"Image cropped to: \" + str(z_size) + \", \" + str(y_size) + \", \" + str(x_size))\n",
    "    latticeMovieImage_all.append(latticeMovieImage_frame)\n",
    "    latticeMovieMask_all.append(latticeMovieMask_frame)\n",
    "    \n",
    "    \n",
    "latticeMovieImage_all =  np.array(latticeMovieImage_all)\n",
    "latticeMovieMask_all = np.array(latticeMovieMask_all)\n",
    "\n",
    "print(latticeMovieImage_all.shape)\n",
    "print(latticeMovieMask_all.shape)\n",
    "print(np.amax(latticeMovieMask_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to discard data with no or few targets in the ground truth\n",
    "def filter_patches(lattice_patches, mask_patches, percent_covered=1e-10):\n",
    "        zero_mask_ids = []\n",
    "        \n",
    "        for patch_index in range (0, mask_patches.shape[0]):\n",
    "            patch = mask_patches[patch_index]\n",
    "            if(np.count_nonzero(patch == 255.0)/(mask_patches.shape[1]**3) < percent_covered): #Means that the mask has all 0s\n",
    "                zero_mask_ids.append(patch_index)\n",
    "        \n",
    "        lattice_patches = np.delete(lattice_patches, zero_mask_ids, axis=0)\n",
    "        mask_patches = np.delete(mask_patches, zero_mask_ids, axis=0)\n",
    "            \n",
    "        return lattice_patches, mask_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1, 8, 8, 1, 32, 32, 32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lattice_patches = view_as_blocks(latticeMovieImage_all, block_shape=(1, cube_size, cube_size, cube_size))\n",
    "lattice_patches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 32, 32, 32)\n",
      "(210, 32, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "# Use the view_as_blocks and reshape methods to slice our frame into cubes.\n",
    "\n",
    "lattice_patches = view_as_blocks(latticeMovieImage_all, block_shape=(1, cube_size, cube_size, cube_size))\n",
    "lattice_patches = lattice_patches.reshape(int(frames)*int(x_size/cube_size)*int(y_size/cube_size)*int(z_size/cube_size), cube_size, cube_size, cube_size)\n",
    "\n",
    "mask_patches = view_as_blocks(latticeMovieMask_all, block_shape=(1, cube_size, cube_size, cube_size))\n",
    "mask_patches = mask_patches.reshape(int(frames)*int(x_size/cube_size)*int(y_size/cube_size)*int(z_size/cube_size), cube_size, cube_size, cube_size)\n",
    "\n",
    "# Change percent_covered to set a threshold of what percent of pixels in the patch need to be signal (1).\n",
    "lattice_patches, mask_patches = filter_patches(lattice_patches, mask_patches, percent_covered=1e-10)\n",
    "print(lattice_patches.shape)\n",
    "print(mask_patches.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place the data ground-truth pair of cubes in their own folder within the quickstart-gendata directory\n",
    "\n",
    "num_train_patches = int(train_split*lattice_patches.shape[0])\n",
    "\n",
    "for k in range(0, num_train_patches):\n",
    "    x_file = lattice_patches[k].astype('uint16')\n",
    "    y_file = mask_patches[k].astype('uint16')\n",
    "    \n",
    "    metadata_x = dict(microscope='joh', shape=x_file.shape, dtype=x_file.dtype.str)\n",
    "    metadata_x = json.dumps(metadata_x)\n",
    "    \n",
    "    metadata_y = dict(microscope='joh', shape=y_file.shape, dtype=y_file.dtype.str)\n",
    "    metadata_y = json.dumps(metadata_y)\n",
    "    \n",
    "    os.mkdir(split_directory+\"train/Region\"+str(k)+\"/\")\n",
    "    tifffile.imwrite(split_directory+\"train/Region\"+str(k)+\"/\"+\"lattice_light_sheet.tif\", x_file, description=metadata_x)\n",
    "    tifffile.imwrite(split_directory+\"train/Region\"+str(k)+\"/\"+\"truth.tif\", y_file, description=metadata_y)\n",
    "    \n",
    "for k in range(num_train_patches, lattice_patches.shape[0]):\n",
    "    x_file = lattice_patches[k].astype('uint16')\n",
    "    y_file = mask_patches[k].astype('uint16')\n",
    "    \n",
    "    metadata_x = dict(microscope='joh', shape=x_file.shape, dtype=x_file.dtype.str)\n",
    "    metadata_x = json.dumps(metadata_x)\n",
    "    \n",
    "    metadata_y = dict(microscope='joh', shape=y_file.shape, dtype=y_file.dtype.str)\n",
    "    metadata_y = json.dumps(metadata_y)\n",
    "    \n",
    "    os.mkdir(split_directory+\"test/Region\"+str(k)+\"/\")\n",
    "    tifffile.imwrite(split_directory+\"test/Region\"+str(k)+\"/\"+\"lattice_light_sheet.tif\", x_file, description=metadata_x)\n",
    "    tifffile.imwrite(split_directory+\"test/Region\"+str(k)+\"/\"+\"truth.tif\", y_file, description=metadata_y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
