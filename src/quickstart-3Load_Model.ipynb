{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dnadeem/Desktop/dl/pyLattice_deepLearning/src/predict.py:35: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  assert offset.size is 3, \"Offset array needs to have a size of 3.\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import skimage\n",
    "import tifffile \n",
    "\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "from keras.utils import CustomObjectScope\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "from dice import dice_coef, dice_loss\n",
    "from predict import predict_mask\n",
    "from visualize import display_slice_from_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"/Users/dnadeem/Desktop/dl/pyLattice_deepLearning/src/quickstart-data/train_data_input.tif\"\n",
    "truth_path = \"/Users/dnadeem/Desktop/dl/pyLattice_deepLearning/src/quickstart-data/mask_all_frames_modified.tif\"\n",
    "model_path = \"jan30_largeframe_32_nonzero_standardized_local.keras\"\n",
    "\n",
    "# Use the same patch_size that was used for training\n",
    "patch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-08 21:43:24.425613: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Pro\n",
      "2024-06-08 21:43:24.425665: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 36.00 GB\n",
      "2024-06-08 21:43:24.425678: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 13.50 GB\n",
      "2024-06-08 21:43:24.425718: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-06-08 21:43:24.425741: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "with CustomObjectScope({'GlorotUniform': glorot_uniform()}):\n",
    "        model = load_model(model_path, custom_objects={'dice': dice_loss(), 'dice_coef': dice_coef})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image cropped to: 256, 256, 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dnadeem/Desktop/dl/pyLattice_deepLearning/src/predict.py:35: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  assert offset.size is 3, \"Offset array needs to have a size of 3.\"\n",
      "/Users/dnadeem/Desktop/dl/pyLattice_deepLearning/src/predict.py:35: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  assert offset.size is 3, \"Offset array needs to have a size of 3.\"\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 3-dimensional, but 4 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Uses the overloaded predict_mask method which can detect the correct size\u001b[39;00m\n\u001b[1;32m      2\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 3\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime to complete: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(end \u001b[38;5;241m-\u001b[39m start))\n",
      "File \u001b[0;32m~/Desktop/dl/pyLattice_deepLearning/src/predict.py:71\u001b[0m, in \u001b[0;36mpredict_mask\u001b[0;34m(model, image_path, patch_size, offset)\u001b[0m\n\u001b[1;32m     68\u001b[0m y_index \u001b[38;5;241m=\u001b[39m y \u001b[38;5;241m*\u001b[39m patch_size\n\u001b[1;32m     69\u001b[0m z_index \u001b[38;5;241m=\u001b[39m z \u001b[38;5;241m*\u001b[39m patch_size\n\u001b[0;32m---> 71\u001b[0m current_lattice_patch \u001b[38;5;241m=\u001b[39m \u001b[43mlatticeMovieImage\u001b[49m\u001b[43m[\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_index\u001b[49m\u001b[43m:\u001b[49m\u001b[43mz_index\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_index\u001b[49m\u001b[43m:\u001b[49m\u001b[43my_index\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mx_index\u001b[49m\u001b[43m:\u001b[49m\u001b[43mx_index\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpatch_size\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     73\u001b[0m current_lattice_patch \u001b[38;5;241m=\u001b[39m current_lattice_patch\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, patch_size, patch_size, patch_size, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     75\u001b[0m result_patch \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(current_lattice_patch)\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 3-dimensional, but 4 were indexed"
     ]
    }
   ],
   "source": [
    "# Uses the overloaded predict_mask method which can detect the correct size\n",
    "start = time.time()\n",
    "mask = predict_mask(model, image_path, patch_size, offset=np.asarray([0,0,0]))\n",
    "end = time.time()\n",
    "print(\"Time to complete: \" + str(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View your prediction file\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [30, 30]\n",
    "plt.set_cmap('gray')\n",
    "z=5\n",
    "\n",
    "display_slice_from_batch(tifffile.imread(image_path)[:mask.shape[1], :mask.shape[2], :mask.shape[3]].reshape(mask.shape), z=z)\n",
    "display_slice_from_batch(tifffile.imread(truth_path)[:mask.shape[1], :mask.shape[2], :mask.shape[3]].reshape(mask.shape), z=z)\n",
    "display_slice_from_batch(mask, z=z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the following if you intend to DOWNLOAD the predicted tif file (optional)\n",
    "prediction_file = (mask*255.0).astype('uint16')\n",
    "metadata = dict(microscope='joh', shape=prediction_file.shape, dtype=prediction_file.dtype.str)\n",
    "metadata = json.dumps(metadata)\n",
    "\n",
    "# Change name of file\n",
    "skimage.external.tifffile.imsave(\"Production2_PSNR100prediction.tif\", prediction_file, description=metadata)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
